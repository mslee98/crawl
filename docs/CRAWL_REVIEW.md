# carrot-rough-crawl.py 크롤링 방식 검토

현재 구조를 기준으로 **속도**, **낭비 요소**, **개선 포인트**를 정리했습니다.

---

## 잘 하고 있는 점

1. **리스트 → 상세 2단계**  
   리스트에서 URL만 모은 뒤 상세를 도는 방식은 당근처럼 상세 정보가 많은 사이트에 적합합니다.

2. **카테고리 필터**  
   리스트에서 카테고리를 쓰면 상세 방문 수를 줄여서 시간을 아낄 수 있고, `ALLOWED_CATEGORIES` / `--categories` 로 선택 가능한 것도 좋습니다.

3. **상세 대기 시간**  
   `DETAIL_PAGE_DELAY_MS`(800ms)로 요청 간격을 두어 과한 부하를 피하는 선택은 타당합니다.

4. **domcontentloaded 사용**  
   상세 페이지는 `wait_until="domcontentloaded"`로 전체 로드보다 빠르게 들어가는 것은 속도 측면에서 유리합니다.

5. **에러 시 빈 값 처리**  
   상세 조회 실패 시 해당 행만 실패 처리하고 나머지는 그대로 저장하는 방식은 실용적입니다.

---

## 속도·낭비 측면에서 지적할 점

### 1. 상세 페이지를 완전히 순차 처리 (가장 큰 병목)

- **현재**: 상세 URL을 **한 건씩** 순서대로 방문합니다.  
  예: 300건이면 `300 × (페이지 로드 + 500ms + 800ms)` 만큼만 걸립니다.
- **영향**: 상세 수집 시간이 전체 실행 시간의 대부분을 차지합니다.
- **개선**:  
  - **병렬 상세 수집**  
    브라우저에서 **페이지(탭) 3~5개**를 열고, `asyncio.gather` 등으로 여러 URL을 동시에 `page.goto` + `evaluate` 하면 체감 속도가 크게 줄어듭니다.  
  - 당근이 rate limit을 걸 수 있으므로 동시 수는 **2~5** 정도로 제한하고, 기존 `DETAIL_PAGE_DELAY_MS`는 “동시 요청 간 간격” 정도로 두는 식으로 조정할 수 있습니다.

### 2. 더보기 클릭 후 고정 1.5초 대기

- **현재**: 더보기 클릭마다 `await page.wait_for_timeout(1500)` 로 무조건 1.5초 대기합니다.
- **영향**: 응답이 0.5초 안에 와도 1초를 더 기다리므로, 클릭 횟수만큼 시간이 낭비됩니다.
- **개선**:  
  - “이전 카드 개수보다 DOM 카드 수가 늘어날 때까지” 폴링 (예: 0.2초 간격, 최대 3~5초) 후 다음 클릭으로 넘어가기.  
  - 또는 `page.wait_for_selector(새 카드 또는 로딩 해제, timeout=5000)` 같은 조건 대기로 바꾸면, 빠를 때는 더 빨리 진행할 수 있습니다.

### 3. 상세 페이지 로드 후 고정 500ms 대기

- **현재**: `page.goto(..., domcontentloaded)` 후 `await page.wait_for_timeout(500)` 으로 무조건 0.5초 대기합니다.
- **영향**:  
  - 이미 필요한 요소가 나온 페이지는 500ms 낭비.  
  - SPA라서 500ms로는 부족한 경우, 가끔 데이터가 비어 나올 수 있음.
- **개선**:  
  - “카테고리나 본문이 들어가는 컨테이너” 같은 **핵심 요소 하나**를 `page.wait_for_selector(..., timeout=5000)` 로 기다린 뒤, 없으면 짧은 fallback 대기(예: 200ms)만 주는 방식이면, 빠른 페이지는 더 빨리, 느린 페이지는 더 안정적으로 수집할 수 있습니다.

### 4. 리스트 첫 로드의 networkidle

- **현재**: 검색 페이지 진입 시 `wait_for_load_state("networkidle")` 사용.
- **영향**: 네트워크가 조금만 있어도 대기가 길어질 수 있어, 첫 화면이 뜨는 데만 보면 다소 과한 대기일 수 있습니다.
- **개선**:  
  - `domcontentloaded` 또는 `load`로 줄이고,  
  - “리스트 카드가 하나라도 보일 때까지” `wait_for_selector(ITEM_SELECTOR, timeout=10000)` 로 대기하는 방식이면, 불필요한 대기를 줄일 수 있습니다. (필요하면 networkidle을 fallback으로만 사용)

### 5. 상세 간 800ms 고정 대기

- **현재**: 상세 1건 처리 후 다음으로 넘어가기 전 `DETAIL_PAGE_DELAY_MS`(800ms) 대기.
- **영향**: 300건이면 이 대기만으로도 300×0.8초 ≈ 4분입니다. 서버 부하는 줄이지만, 속도는 희생됩니다.
- **개선**:  
  - 병렬 수집(예: 3~5개 동시)을 도입하면 “동시 요청 수”로 나눠서 체감 부담이 줄어듭니다.  
  - 당근이 차단을 안 한다고 가정할 때만, 400~500ms로 낮추는 것도 선택지입니다. (현재처럼 800ms 유지해도 “안전 우선”으로는 타당합니다.)

### 6. URL 중복 미처리

- **현재**: 리스트에서 뽑은 그대로 상세 방문합니다.
- **영향**: 끌올/정렬 때문에 같은 글이 리스트에 두 번 나오면, 같은 URL을 두 번 방문하게 됩니다.
- **개선**:  
  - 리스트 추출 직후 `url` 기준으로 중복 제거한 뒤 `items_to_detail`을 만들면, 불필요한 상세 방문이 줄어듭니다.

### 7. 상세 수집 실패 건도 대기 시간은 동일

- **현재**: 상세 조회가 실패해도 `DETAIL_PAGE_DELAY_MS` 를 그대로 적용합니다.
- **영향**: 404/타임아웃 등으로 빨리 실패한 경우에도 800ms를 기다리게 됩니다.
- **개선**:  
  - 실패한 경우에는 대기 시간을 짧게(예: 200ms) 하거나 생략하는 식으로 조정하면, 실패가 많은 날에는 전체 시간이 조금 줄어듭니다.

---

## 요약 표

| 항목 | 현재 | 영향 | 개선 방향 |
|------|------|------|-----------|
| 상세 수집 | 순차 1건씩 | 전체 시간의 대부분 | 2~5개 페이지 병렬 수집 |
| 더보기 후 대기 | 고정 1500ms | 클릭마다 낭비 가능 | 카드 수 증가 또는 selector 대기 |
| 상세 로드 후 | 고정 500ms | 빠른 페이지에서 낭비 | 핵심 요소 wait_for_selector |
| 리스트 첫 로드 | networkidle | 첫 화면 대기 과할 수 있음 | domcontentloaded + 카드 selector 대기 |
| 상세 간격 | 800ms | 많은 건수일 때 누적 | 병렬화 또는 400~500ms 검토 |
| URL 중복 | 미처리 | 같은 글 여러 번 상세 방문 | url 기준 중복 제거 |
| 실패 후 대기 | 800ms 동일 | 실패 많을 때 누적 | 실패 시 짧은 대기 또는 생략 |

---

## 결론

- **구조(리스트 → 상세, 카테고리 필터, 대기 시간 존재)** 자체는 타당하고, 당근 같은 사이트에 맞는 방식입니다.
- **속도·낭비** 측면에서 가장 효과적인 개선은 **상세 페이지를 소수(2~5) 병렬로 수집**하는 것입니다.  
  그 다음으로 **더보기 후 조건부 대기**, **상세 로드 후 selector 대기**, **URL 중복 제거**를 적용하면 추가로 시간을 줄이고 안정성을 높일 수 있습니다.
- **차단/매너**를 고려하면, 병렬 수는 3~5 이하, 상세 간격은 400~800ms 유지하는 쪽을 권장합니다.

### ✅ 반영된 개선 (carrot-rough-crawl.py)

| 항목 | 반영 내용 |
|------|------------|
| 1. 병렬 상세 수집 | `DETAIL_PAGE_CONCURRENCY=4`, 여러 `browser.new_page()`로 동시 수집 후 `asyncio.gather` |
| 2. 더보기 조건부 대기 | 고정 1.5초 → 카드 수 증가 시까지 폴링 (200ms 간격, 최대 5초) |
| 3. 상세 로드 후 대기 | 고정 500ms → `#main-content article` `wait_for_selector`(5초) 후 실패 시 200ms fallback |
| 4. 리스트 첫 로드 | `networkidle` → `domcontentloaded` + `wait_for_selector(ITEM_SELECTOR, 10초)` |
| 5. 상세 간격 | 배치 단위로 800ms; 실패 시 200ms (`DETAIL_PAGE_DELAY_MS_ON_FAIL`) |
| 6. URL 중복 | 리스트 추출 직후 `url` 기준 중복 제거 |
| 7. 실패 시 대기 | 상세 실패가 하나라도 있으면 다음 배치 전 200ms만 대기 |

원하면 “병렬 상세 수집”이나 “더보기 조건부 대기” 중 하나부터 코드 수준으로 어떻게 바꿀지 단계별로 적어줄 수 있습니다.
